
## Nesne Tespit Modellerinin Araştırılması

Nesne tespiti (Object Detection), bir görüntü veya video içerisinde yer alan nesnelerin hangi sınıfa ait olduklarının ve görüntü üzerindeki konumlarının (bounding box) eş zamanlı olarak belirlenmesi problemidir. Görüntü sınıflandırmadan farklı olarak, nesne tespiti yalnızca “ne var?” sorusunu değil, aynı zamanda “nerede?” sorusunu da yanıtlar. Bu nedenle bilgisayarlı görü alanında daha karmaşık ve kritik bir problemdir. Geliştirilen modeller hız, doğruluk ve donanım gereksinimleri açısından farklı yaklaşımlar sunmaktadır.

---

## Nesne Tespitinde Devrimsel Gelişmeler

### Geleneksel Yöntemler

#### 2001 – Viola-Jones Dedektörü (Gerçek Zamanlı Tespitin Doğuşu)

Paul Viola ve Michael Jones tarafından geliştirilen bu algoritma, herhangi bir ön kısıtlama kullanmadan (örneğin deri rengi segmentasyonu olmaksızın) insan yüzlerinin gerçek zamanlı olarak tespit edilebilmesini sağlayan ilk yöntemdir. Algoritma, kayan pencere (sliding window) yaklaşımına dayanmakta olup, işlem yükünü azaltmak amacıyla İntegral Görüntü tekniğini ve Detection Cascade yapısını literatüre kazandırmıştır. Bu yenilikler sayesinde yüz tespiti pratik ve yaygın olarak kullanılabilir hale gelmiştir.

---

#### 2005 – HOG (Histogram of Oriented Gradients)

HOG yöntemi, özellikle yaya tespiti probleminde bir standart haline gelmiştir. Görüntüdeki kenar ve şekil bilgilerini gradyan yönelimleri üzerinden tanımlayarak nesneleri tespit eder. Viola-Jones’a kıyasla daha karmaşık şekilleri temsil edebilse de, farklı ölçeklerdeki nesneleri algılayabilmek için görüntünün defalarca yeniden boyutlandırılması (image pyramid) gerekmektedir. Bu durum hesaplama maliyetini artırmıştır.

---

#### 2008 – DPM (Deformable Part-based Model)

Geleneksel yöntemlerin zirvesi olarak kabul edilen DPM, nesneleri bir bütün olarak değil, parçalarına ayırarak tespit etmeyi önermiştir. Örneğin bir araba; tekerlek, cam ve gövde gibi parçaların ayrı ayrı tespit edilmesi ve bu parçaların ilişkisel bir modelle birleştirilmesiyle algılanmaktadır. Bu yaklaşım doğruluğu artırmış olsa da, karmaşık yapısı ve yüksek hesaplama maliyeti nedeniyle sınırlı kalmıştır.

---

### Derin Öğrenme Dönemi

2012 yılında AlexNet’in ImageNet yarışmasında elde ettiği büyük başarıyla birlikte, CNN mimarilerinin görüntü sınıflandırmadaki üstünlüğü kanıtlanmıştır. Bu başarının ardından CNN tabanlı yaklaşımlar hızla nesne tespiti problemine de uyarlanmıştır.

---

#### 2014 – R-CNN (Regions with CNN Features)

R-CNN, derin öğrenmeyi nesne tespitine entegre eden ilk büyük atılımdır. Bu yöntemde, görüntü üzerinden Selective Search algoritması ile aday bölgeler çıkarılır ve her bir bölge ayrı ayrı bir CNN’e verilerek sınıflandırılır. Bu yaklaşım, DPM’e kıyasla doğrulukta büyük bir sıçrama yaratmış (mAP: %33.7 → %58.5), ancak binlerce bölgenin tek tek işlenmesi nedeniyle oldukça yavaş kalmıştır.

---

#### 2015 – Fast R-CNN ve Faster R-CNN

R-CNN’in hız problemini çözmek amacıyla geliştirilen Fast R-CNN, aday bölgeleri ayrı ayrı işlemek yerine tüm görüntüden tek seferde bir özellik haritası çıkararak işlemi önemli ölçüde hızlandırmıştır. Faster R-CNN ise bölge önerisi (region proposal) adımını da bir sinir ağına devrederek (end-to-end) eğitilebilir ilk nesne tespit mimarisini sunmuştur.

---

#### 2016 – YOLO (You Only Look Once) ve Tek Aşamalı Modeller

Önceki modeller nesne tespitini iki aşamada (bölge önerisi + sınıflandırma) gerçekleştirirken, YOLO bu süreci tek bir regresyon problemi olarak ele almıştır. Görüntüyü grid yapısına bölerek tek bir ileri besleme adımıyla tüm nesneleri tespit eder. Bu yaklaşım, özellikle küçük nesnelerde doğruluğu bir miktar düşürse de, çok büyük bir hız artışı sağlamış ve gerçek zamanlı uygulamaların önünü açmıştır.

---

#### 2016 – SSD (Single Shot MultiBox Detector)

SSD, YOLO’nun küçük nesnelerde yaşadığı zorlukları azaltmak amacıyla geliştirilmiştir. Farklı ölçeklerdeki özellik haritalarını kullanarak çoklu çözünürlükte tahmin yapabilen SSD, hız ve doğruluk arasında daha dengeli bir yapı sunmuştur.

---

#### 2017 – FPN (Feature Pyramid Networks) ve RetinaNet

Nesne tespitinde ölçek problemini çözmek için **Feature Pyramid Network (FPN)** yapısı önerilmiştir. Bu yapı sayesinde hem küçük hem de büyük nesneler aynı ağ içerisinde daha etkili biçimde tespit edilebilmektedir. Aynı dönemde geliştirilen RetinaNet modeli ise, tek aşamalı dedektörlerde sıkça görülen sınıf dengesizliği problemini çözmek için **Focal Loss** fonksiyonunu literatüre kazandırmıştır.

---

### Modern Dönem: Transformer Mimarileri

#### 2020 – DETR (Detection Transformer)

DETR, bilgisayarlı görü alanında Transformer mimarisinin (dikkat mekanizmasının) başarılı bir uygulamasıdır. Önceki modellerde kullanılan **anchor box** ve **Non-Maximum Suppression (NMS)** gibi manuel ayar gerektiren adımları tamamen ortadan kaldırmıştır. Nesne tespitini bir **küme tahmin problemi** olarak ele alan DETR, sade ve tamamen uçtan uca öğrenilebilir bir mimari sunmaktadır.

---

### CNN Tabanlı Modellerin Önceki Yöntemlerden Farkı ve CNN Yapısının Mantığı

CNN tabanlı modellerden önce nesne tespiti problemleri, Viola-Jones, HOG ve DPM gibi yöntemlerle çözülmekteydi. Bu yaklaşımlarda hangi görsel özelliklerin kullanılacağı önceden insan tarafından belirleniyor model bu tanımlı özellikler üzerinden karar veriyordu. Bu durum sistemlerin belirli senaryolarda iyi çalışmasına rağmen farklı aydınlatma koşulları, karmaşık arka planlar ve farklı nesne türleri karşısında genelleme yapmasını zorlaştırıyordu.

CNN tabanlı yaklaşımlar ile birlikte bu bakış açısı tamamen değişmiştir. CNN’lerin en önemli farkı görüntüdeki hangi özelliklerin önemli olduğuna insanın değil modelin kendisinin karar vermesidir. Model, ham görüntüyü doğrudan giriş olarak alır ve eğitim süreci boyunca nesneyi tanımlamak için gerekli olan görsel örüntüleri otomatik olarak öğrenir. Bu durum, nesne tespitinde insan müdahalesini azaltırken modelin farklı koşullara daha iyi uyum sağlamasını mümkün kılar.

CNN yapısının mantığı incelendiğinde öğrenmenin katmanlı ve hiyerarşik bir şekilde gerçekleştiği görülmektedir. İlk evrişim katmanlarında kenar, köşe ve basit dokular gibi düşük seviyeli özellikler öğrenilir. Daha derin katmanlara ilerledikçe bu basit yapılar birleştirilerek nesne parçaları ve daha soyut temsiller elde edilir. Bu süreç, modelin bir nesneyi parça parça değil, bütüncül bir yapı olarak algılamasını sağlar.

Evrişim katmanları, görüntü üzerindeki yerel ilişkileri koruyarak özellik çıkarımı yaparken, havuzlama(pooling) katmanları hesaplama maliyetini azaltır ve küçük konumsal değişimlere karşı dayanıklılık kazandırır.Bu sayede CNN tabanlı modeller, nesnenin görüntüdeki tam konumu biraz değişse bile doğru tahmin yapabilir.

Bu yapıyı anlamak açısından CNNleri, bir görüntüyü insan gözüne benzer şekilde adım adım inceleyen sistemler olarak düşünmek mümkündür.İnsanlar da bir nesneyi ilk bakışta kenarları ve şekliyle algılar ardından bu bilgileri birleştirerek nesnenin ne olduğuna karar verir.CNNler de benzer biçimde, basitten karmaşığa doğru ilerleyen bir öğrenme süreci uygular.

Son aşamada yer alan sınıflandırma ve konum regresyon katmanları, öğrenilen bu özellikleri kullanarak nesnenin hangi sınıfa ait olduğunu ve görüntü üzerindeki konumunu tahmin eder. Bu end-to-end öğrenme yaklaşımı sayesinde CNN tabanlı modeller, geleneksel yöntemlere kıyasla hem daha esnek hem de daha yüksek doğruluk sunan sistemler haline gelmiştir.


 ### Nesne Tespitinde Kullanılan Başlıca Modeller

Endüstriyel uygulamalarda(otonom araçlar, güvenlik kameraları, akıllı şehir sistemleri, endüstriyel kalite kontrol ve medikal görüntüleme gibi) kullanulan nesne tespit modellerini iki aşamalı tek aşamalı ve transformer tabanlılar olacak şekilde ayırabiliriz. 


---

#### İki Aşamalı MOdeller 

İki aşamalı nesne tespit modelleri, tespit problemini ardışık iki temel adımda ele alır. İlk adımda görüntü üzerinde nesne bulunma ihtimali yüksek olan bölgeler belirlenir. İkinci adımda ise bu aday bölgeler detaylı biçimde analiz edilerek hem sınıflandırma yapılır hem de sınır kutularının (bounding box) konumu hassas şekilde iyileştirilir. Bu yaklaşım, yüksek doğruluk sağlamasına rağmen işlem süresini artırmaktadır.

**Faster R-CNN (2015)**  
Bu model, iki aşamalı yaklaşımlar arasında doğruluk açısından uzun süre endüstri standardı olarak kabul edilmiştir. Önceki yöntemlerde kullanılan yavaş bölge öneri algoritmalarının yerine, bu işlemi doğrudan ağın bir parçası haline getiren Region Proposal Network (RPN) yapısını kullanır.

**Çalışma Mantığı:**  
Görüntüden çıkarılan özellikler üzerinden çalışan RPN, nesne olma olasılığı yüksek bölgeleri belirler. Bu bölgeler ikinci aşamada sınıflandırma ve konumlandırma işlemlerinden geçirilir. Böylece model, uçtan uca eğitilebilir bir yapıya kavuşur.

**Avantajları:**  
Yüksek doğruluk ve hassas konumlandırma sağlar. Özellikle küçük ve karmaşık nesnelerin tespitinde başarılıdır.

**Dezavantajları:**  
Tek aşamalı modellere kıyasla daha yavaş çalışır ve yüksek hesaplama gücü gerektirir.

**Kullanım Alanları:**  
Tıbbi görüntü analizi, endüstriyel kalite kontrol, savunma ve güvenlik sistemleri gibi doğruluğun hızdan daha önemli olduğu uygulamalarda tercih edilmektedir.

---

#### Tek Aşamalı Nesne Tespit Modelleri

Tek aşamalı nesne tespit modelleri, bölge önerisi adımını tamamen ortadan kaldırarak tespit ve sınıflandırma işlemlerini tek bir ileri besleme (forward pass) ile gerçekleştirir. Bu yaklaşımlar, hız odaklı yapıları sayesinde gerçek zamanlı uygulamalarda yaygın olarak tercih edilmektedir.

**YOLO (You Only Look Once) (2015 – Günümüz)**  
YOLO, nesne tespitini tek bir regresyon problemi olarak ele alarak bu alanda önemli bir paradigma değişimi yaratmıştır. Görüntü, sabit boyutlu bir ızgaraya bölünür ve her hücre için sınıf olasılıkları ile sınır kutusu (bounding box) tahminleri eş zamanlı olarak üretilir.

**Gelişimi:**  
İlk sürümleri yüksek hız sağlamasına rağmen küçük nesnelerin tespiti ve konumlandırma doğruluğu açısından sınırlı kalmıştır. Daha sonraki sürümlerde (YOLOv3, YOLOv4, YOLOv7 vb.) çok ölçekli özellik haritaları ve gelişmiş kayıp fonksiyonları kullanılarak hız ve doğruluk dengesi önemli ölçüde iyileştirilmiştir.

**Kullanım Alanları:**  
Otonom sürüş sistemleri, drone tabanlı görüntü analizi, güvenlik kameraları ve canlı video işleme uygulamaları.

---

**SSD (Single Shot MultiBox Modeli) (2016)**  
SSD, tek aşamalı yaklaşımların hız avantajını korurken tespit doğruluğunu artırmayı amaçlamıştır. Temel farkı, nesne tespitini yalnızca ağın son katmanında değil, farklı derinliklerdeki ara katmanlar üzerinden de gerçekleştirmesidir.

**Avantajı:**  
Küçük nesneler erken katmanlardaki yüksek çözünürlüklü özellikler yardımıyla, büyük nesneler ise daha derin katmanlardaki güçlü anlamsal temsiller kullanılarak tespit edilir. Bu yaklaşım, farklı ölçeklerdeki nesnelerin aynı anda yakalanmasını sağlar.

---

**RetinaNet (2017)**  
RetinaNet, tek aşamalı yaklaşımların iki aşamalı modellere kıyasla daha düşük doğruluk sergilemesinin temel nedenini sınıf dengesizliği problemi olarak ele almıştır.

**Yeniliği:**  
"Focal Loss" adı verilen kayıp fonksiyonu sayesinde model, eğitim sırasında kolay örneklerin (özellikle arka plan) etkisini azaltarak zor ve nadir nesnelere odaklanır. Bu yaklaşım, tek aşamalı modellerin doğruluğunu önemli ölçüde artırmıştır.

---

#### Anchor-Free ve Transformer Tabanlı Nesne Tespit Modelleri

2019 sonrası geliştirilen bu modeller, önceden tanımlı sınır kutularına (anchor boxes) olan bağımlılığı ortadan kaldırarak daha sade ve esnek mimariler sunmaktadır.

**CenterNet (2019)**  
CenterNet, nesneleri doğrudan bir sınır kutusu yerine merkez noktaları (keypoints) üzerinden modelleyen bir yaklaşımdır. Model, nesnenin merkezini tespit ettikten sonra boyut bilgisini regresyon yöntemiyle tahmin eder.

**Avantajı:**  
Anchor box tanımı ve NMS gibi işlem sonrası adımlara ihtiyaç duymadan uçtan uca çalışabilmesi, modeli daha sade ve hızlı hale getirir.

---

**DETR (Detection Transformer) (2020)**  
DETR, nesne tespit problemini CNN tabanlı yaklaşımlardan farklı olarak Transformer mimarisi üzerinden ele alır. Dikkat (attention) mekanizmaları sayesinde görüntüyü küresel olarak analiz eder ve nesneler arasındaki ilişkileri bütüncül biçimde öğrenir.

**Çalışma Mantığı:**  
Nesne tespiti, bir küme tahmin problemi (set prediction) olarak ele alınır. Bu sayede anchor box, NMS ve manuel eşik değerlerine duyulan ihtiyaç ortadan kalkar.

**Dezavantajı:**  
Eğitim süresi uzun ve veri ihtiyacı fazladır. Buna rağmen mimari sadeliği ve teorik gücü nedeniyle geleceğin nesne tespit yaklaşımları arasında önemli bir yere sahiptir.

--- 
--- 

## YOLO nedir ve Nasıl Çalışır?

YOLO (You Only Look Once),nesne tespitini tek bir ileri besleme adımında gerçekleştiren, hız odaklı bir derin öğrenme algoritmasıdır.Geleneksel yaklaşımlardan farklı olarak YOLO, görüntüyü parçalara ayırıp her parçayı ayrı ayrı analiz etmek yerine, tüm görüntüyü tek seferde ele alır. Bu yaklaşım sayesinde hem nesnenin sınıfını hem de konumunu aynı anda tahmin edebilir.


##### Nasıl Çalışır?
**Temel çalışma prensibi**, nesne tespitini bir sınıflandırma problemi yerine bir regresyon problemi olarak ele almasıdır. 

Girdi görüntüsü SxS boyutunda bir ızgaraya/gride bölünür(örneğin 7x7 13x13 gibi).Görüntüdeki bir nesnenin merkezi hangi ızgara hücresine(grid cell) denk geliyorsa o nesneyi tespit etmekten o hücre sorumludur.

Her bir grid cell, o bölgede bir nesne olup olmadığını tahmin etmek için B adet bounding box öngörür.Her bounding box için 5 temel parametre üretilir:
x, y: Boxın merkez koordinatları
w, h: Boxın genişliği ve yüksekliği
Confidence Score(Güven Skoru): Kutunun içinde bir nesne olma olasılığı ile tahmin edilen kutunun gerçek kutuyla(Ground Truth) ne kadar örtüştüğünü(IoU-Intersection over Union) gösteren değer

Bounding box tahminlerine paralel olarak her grid cell o bölgedeki nesnenin hangi sınıfa (araba, kedi vb.) ait olduğuna dair bir olasılık dağılımı(C) üretir ve bu işlem matematiksel olarak tek bir CNN üzerinden yürütülür.

Sonuç olarak SxSx(Bx5+C) boyutunda bir tensör (tensor) elde edilir.

Model doğası gereği bir nesne için birden fazla bounding vox üretebilir.Bu da aynı nesne üzerinde çok sayıda üst üste binmiş box oluşmasına neden olur.Non-Maximum Suppression(NMS) algoritması devreye girerek:

Güven skoru belirli bir eşik değerin(threshold) altında olan kutuları siler.

Kalan kutular arasında IoU değeri yüksek olan(fazla örtüşen) kutulardan sadece en yüksek skora sahip olanı tutar diğerlerini bastırır(suppress).

---
##### Özetle
Bu yapı sayesinde YOLO, görüntüdeki nesneleri bütüncül bir bakış açısıyla değerlendirir. Model, nesneler arasındaki bağlamsal ilişkileri öğrenebilir ve arka plan ile nesne arasındaki farkı daha net şekilde ayırt edebilir. Özellikle gerçek zamanlı uygulamalarda önemli durumdur.

En güçlü yönlerinden biri hızıdır.Tüm işlemler tek bir sinir ağı üzerinde gerçekleştiği için, video akışları ve canlı kamera görüntüleri üzerinde gerçek zamanlı nesne tespiti yapmak mümkündür.

İlk sürümleri küçük nesnelerin tespitinde ve nesnelerin birbirine çok yakın olduğu sahnelerde sınırlı performans göstermiştir.Ancak sonraki sürümlerde yapılan mimari iyileştirmeler, çok ölçekli özellik çıkarımı ve daha gelişmiş kayıp fonksiyonları sayesinde bu dezavantajlar büyük ölçüde giderilmiştir. Kısaca YOLO, nesne tespitini hızlı, sade ve end to end öğrenilebilir bir yapıya dönüştürür.Görüntüyü “bir bütün olarak” analiz etmesi, onu klasik yöntemlerden ayıran en temel özelliktir.

---
### YOLO özelinde loss functions (box_loss, cls_loss, val_loss) ve mAP 

#### Toplam kayıp(Total Loss):
YOLO'nun toplam kaybı (Total Loss), genellikle üç farklı hata türünün ağırlıklı toplamından oluşur. Literaturdeki ifade ediliş şekli: 

$$
L_{total} = \lambda_{box} L_{box} + \lambda_{obj} L_{obj} + \lambda_{cls} L_{cls}
$$

**1 - box_loss (bounding box loss/localization Loss)**  

Modelin tahmin ettiği bounding box ile gerçek(ground truth) bounding box arasındaki farkı ölçer.Bu fark kutunun merkezi (x, y), genişliği ve yüksekliği üzerinden hesaplanır.İlk YOLO sürümlerinde(v1, v2) hata kareler ortalaması(MSE/L2 Loss) kullanılmaktaydı. Ancak bu yöntem, boxın geometrik yapısını tam yansıtmadığı için güncel YOLO sürümlerinde bu kayıp genellikle IoU tabanlı metrikler (GIoU, DIoU, CIoU) kullanılarak hesaplanır. 

kısaca: box_loss ne kadar düşükse model nesneyi o kadar keskin bir çerçeve içine alıyor demektir.

**2- cls_loss (Sınıflandırma Kaybı/Classification Loss)**

Tespit edilen nesnenin hangi sınıfa ait olduğunun ne kadar doğru tahmin edildiğini ölçer. Modelin tahmin ettiği sınıf olasılıkları ile gerçek sınıf etiketi karşılaştırılır.

Genellikle Cross-Entropy(Çapraz Entropi) veya Binary Cross-Entropy kullanılır.Bu fonksiyon, olasılık dağılımları arasındaki farkı ölçer(L2 Loss'a göre sınıflandırmada daha başarılıdır).

Örn: Model bir "insan" görüntüsüne %80 "insan", %20 "arka plan" diyorsa ve gerçek etiket %100 "insan" ise aradaki bu olasılık farkı cls_loss olarak cezalandırılır.

YOLO tek bir bounding box için birden fazla sınıf olasılığı üretebildiği için bu kayıp fonksiyonu sınıflar arasındaki ayrımı öğrenmede kritik bir rol oynar.

kısaca: class lossun düşük olması modelin nesneleri doğru kategorilere ayırabildiğini gösterir.


**3-val_loss (Doğrulama Kaybı/Validation Loss)**

Bu kayıp, tahmin edilen bounding box içinde gerçekten bir nesne olup olmadığını ölçer. YOLO, her kutu için bir “nesne var mı?” olasılığı üretir.Eğitimin başarısını ölçen bir sonuç metriğidir. Tanım olarak da modelin eğitim sırasında hiç görmediği veri seti (validation set) üzerindeki toplam hatasıdır diybiliriz.

Modelin yanlış pozitifleri (arka planı nesne sanması) ve yanlış negatifleri (nesneyi kaçırması) azaltmasını sağlar.Validation loss, eğitim sürecinde modelin genelleme başarısını takip etmek için kullanılır ve overfitting durumlarını gözlemlemede önemlidir.

kısaca: eğer eğitim kaybı(train loss) düşerken val_loss yükselmeye başlarsa model ezberlemeye (overfitting) başlamış demektir.İdeal olan her ikisinin de paralel olarak düşmesidir. 

#### mAP(Mean Average Precision)

Bir nesne tespit modelinin başarısını doğruluk oranı %90 gibi tek bir sayıyla ifade etmek zordur çünkü hem nesneyi bulup bulmadığı hem de boxı ne kadar doğru çizdiği önemlidir. mAP bu karmaşıklığı standartlaştıran metriktir.

Precision(Kesinlik):Tahmin ettiklerimin kaçı doğru?

Recall (Duyarlılık):Gerçektekilerin kaçını bulabildim?

AP(Average Precision):Precision-Recall eğrisinin altında kalan alandır. Her sınıf (örneğin araba, insan) için ayrı ayrı hesaplanır.

mAP(mean AP):Tüm sınıfların AP değerlerinin ortalamasıdır.

Önemli Bir Ayrım(IoU Eşiği):Bir tahminin doğru sayılması için IoU eşiği(threshold) önemlidir.

mAP@0.5: Eğer tahmin edilen kutu ile gerçek kutu %50'den fazla örtüşüyorsa doğru kabul edilir. Bu, PASCAL VOC standardıdır.

mAP@0.5:0.95: COCO veri seti standardıdır. 0.5'ten 0.95'e kadar farklı eşiklerde mAP hesaplanıp ortalaması alınır. Bu metrik, konumsal hassasiyeti(localization accuracy) daha sıkı ölçer.

---

### YOLO özelinde Temel Hyperparametreler

YOLO’nun performansı, mimarinin yanı sıra kullanılan hyperparametrelere de büyük ölçüde bağlıdır. Hiperparametreler, modelin eğitim sırasında öğrenmediği, bizim eğitimden önce "elle ayarladığımız" değişkenlerdir.

#### Learning Rate
Modelin ağırlıklarını ne kadar hızlı güncelleyeceğini belirler. Çok yüksek seçildiğinde eğitim kararsız hale gelir, çok düşük seçildiğinde ise öğrenme yavaşlar.

#### Anchors (Çapa Kutuları):YOLO, nesneleri sıfırdan tahmin etmek yerine, önceden tanımlanmış şablon kutuları(anchors) referans alır. Bu kutuların boyutları ve en-boy oranları (aspect ratios), veri setindeki nesnelere göre (örneğin k-means kümeleme ile) belirlenmelidir.

#### Input Size: Ağın giriş çözünürlüğüdür (Örn: 416x416, 640x640).Boyut artarsa küçük nesneleri tespit yeteneği artar ancak işlem hızı (FPS) düşer.

#### IoU Threshold(NMS Eşiği): Aynı nesne için üretilen birden fazla kutuyu elerken kullanılan Non-Maximum Suppression eşiğidir.

#### Confidence Threshold: Modelin bir tahmini "var" sayması için gereken minimum güven skoru (örn 0.25).

#### Epoch Sayısı Eğitim verisinin model tarafından kaç kez görüleceğini ifade eder. Yetersiz epoch underfitting’e, fazla epoch ise overfitting’e yol açabilir.


---

### YOLO'nun farklı modeleri(segmentation, detection) arasındaki farklar ve sürümler arasındaki (s, m, l, x) farklar nelerdir? Bu farkları yaratan temel unsurlar nelerdir? 

YOLO mimarisi endüstriyel ihtiyaçlara göre hem yapısal işlev hem de model kapasitesi bakımından farklı varyasyonlara ayrılır. 

**YOLO Detection**

Bu model türü, görüntüdeki nesnelerin sınıfını ve konumunu (bounding box) tahmin eder.

Örneğin bir trafikteki araçları tespit etmek istiyorsak model bize her aracın türünü ve hangi koordinatlarda olduğunu verir. Çıktı sadece sınıf + konum olduğu için, işlem yükü daha düşüktür ve gerçek zamanlı uygulamalara uygundur.

Mimari:Omurga(Backbone) ve Boyun(Neck) katmanlarından gelen özellikler, sadece kutu regresyonu ve sınıflandırma yapan bir "Detection Head"e bağlanır.

**YOLO Segmentation**

Bu model, nesneleri sadece boxlarla değil, piksel seviyesinde maske ile tahmin eder.

Örneğin medikal görüntüde bir tümörün tam alanını göstermek veya üretim hattında bir parçanın sınırlarını detaylı tespit etmek istiyorsak segmentation gerekir. Çıktı hem sınıf + konum hem de nesne maskesi, yani piksel tabanlı harita içerir. Bu nedenle daha hesaplama yoğun ve genellikle daha yavaştır, ama çok daha detaylı bilgi verir. Kısaca "Nesnenin tam şekli nasıldır?" sorusuna cevap verir.

Mimari: Detection Head'e ek olarak, "Mask Head" veya "Proto-net" adı verilen bir dal daha eklenir. Bu dal, kutu içindeki piksellerin nesneye ait olup olmadığını (binary classification) sınıflandırır. Bu, literatürde belirtilen, nesne tespiti ile diğer görevlerin (segmentasyon gibi) tek bir çerçevede birleştirilmesi prensibine dayanır.

---

#### YOLO Sürümleri (s, m, l, x)

Modern YOLO sürümleri (v5, v8 vb.), "Compound Scaling" (Bileşik Ölçeklendirme) adı verilen bir yöntemle aynı mimariyi farklı boyutlarda sunar. Bu boyutlar Nano (n), Small (s), Medium (m), Large(l) ve X-Large(x) olarak adlandırılır.

Bu modeller arasındaki farkı yaratan 3 temel matematiksel unsur vardır:

Depth(Derinlik/Katman Sayısı):Ağın ne kadar derin olduğu, yani kaç adet evrişim (convolution) bloğunun arka arkaya eklendiğidir. Derin ağlar daha soyut ve karmaşık özellikleri öğrenebilir ancak işlem süresi uzar. **Daha fazla katman, daha karmaşık özelliklerin öğrenilmesini sağlar.**

Width(Genişlik/Kanal Sayısı):Her katmandaki filtre (kernel) sayısıdır. Genişlik arttıkça ağın bilgi taşıma kapasitesi artar, ancak parametre sayısı karesel olarak artar. **Daha fazla kanal, her katmanda daha zengin bilgi temsilini mümkün kılar.**

Resolution(Çözünürlük):Eğitim sırasında kullanılan giriş görüntüsünün boyutudur(örn 640x640 vs 1280x1280).


- **s (small)**  
  Daha az parametre içerir, hızlıdır ve düşük donanımlarda çalışmaya uygundur. Gerçek zamanlı uygulamalarda tercih edilir ancak doğruluğu daha büyük modellere göre düşüktür.

- **m (medium)**  
  Hız ve doğruluk arasında dengeli bir yapı sunar. Çoğu genel amaçlı projede tercih edilen orta seviye çözümdür.

- **l (large)**  
  Daha derin ve geniş bir ağ yapısına sahiptir. Özellikle karmaşık sahnelerde ve küçük nesnelerin tespitinde daha başarılıdır ancak daha fazla GPU belleği gerektirir.

- **x (extra large)**  
  En yüksek doğruluğu hedefler. Parametre sayısı ve hesaplama maliyeti oldukça yüksektir. Gerçek zamanlıdan çok, offline veya araştırma odaklı kullanımlar için uygundur.


---

### YOLO için İdeal Dataset Özellikleri 

**Düşük Yanlılık (Low Bias) ve Çeşitlilik**
Veri seti, modelin karşılaşabileceği tüm senaryoları kapsamalıdır. Sadece ideal ışıkta çekilmiş fotoğraflar kullanılırsa, model karanlık ortamda başarısız olur. Veri setlerinin daha az yanlılığa sahip olması gelişmiş algoritmaların geliştirilmesi için esastır.
  
**Sınıf dengesi gözetilmelidir**  
Bazı sınıfların çok fazla, bazılarının çok az olması modelin yanlı öğrenmesine neden olur.

**Doğru ve tutarlı etiketlenmiş olmalıdır**  
Yanlış çizilmiş bounding box’lar veya hatalı sınıf etiketleri, modelin yanlış öğrenmesine yol açar.

**Gerçek kullanım senaryosunu temsil etmelidir**  
Model nerede kullanılacaksa, veri seti de o ortamı yansıtmalıdır.

**Yeterli veri miktarına sahip olmalıdır**  
Az veriyle eğitim mümkündür ancak genelleme başarısı düşer. Veri az ise augmentation daha kritik hale gelir.

---

### Augmentation(Veri Artırma) Nedir ve Nasıl Olmalıdır?

Öncelikle veri artırma, eldeki veri setindeki görüntülerden sentetik türevler oluşturarak veri sayısını ve çeşitliliğini yapay olarak artırma işlemidir. Matematiksel olarak bu işlem, eğitim verisinin dağılımını genişleterek modelin aşırı öğrenmesini (overfitting) engellemeyi ve "değişmezlik" (invariance) kazanmasını amaçlar. 

**Nasıl Olmalıdır?**
- Rotasyon ve Ölçek Dayanıklılığı: Yüz tespiti veya hava fotoğrafları gibi alanlarda nesneler farklı açılarda olabilir. en basit çözüm veri artırma yoluyla nesnenin döndürülmüş hallerini veri setine eklemektir.
- Alan Uyarlaması (Domain Adaptation): Eğitim verisi ile gerçek dünya verisi arasındaki farkı (domain gap) kapatmak için kullanılır. Örneğin, farklı aydınlatma koşulları (parlaklık, kontrast değişimi) simüle edilmelidir.

YOLO için yaygın augmentation örnekleri:
- döndürme (rotation)
- ölçekleme (scaling)
- kırpma (cropping)
- yatay/dikey çevirme (flip)
- parlaklık ve kontrast değişimleri
- gürültü ekleme

---

### Roboflow nedir ve nasıl kullanılır? Veri etiketleme nasıl yapılır?

**Roboflow**, computer vision projeleri için veri setlerini yönetme, etiketleme ve model eğitimine hazır hale getirme platformudur. Hem veri yükleme hem de annotation(etiketleme) işlemleri oldukça hızlı bir şekilde yapılabilir.

**Nasıl Kullanılır?**

Veri Yükleme: Ham fotoğraflar veya videolar sisteme yüklenir.

Etiketleme(Annotation): Platformun arayüzü üzerinden nesnelerin etrafına kutu çizilir. Roboflow'un "Smart Polygon" gibi özellikleri, nesneyi otomatik seçerek etiketlemeyi hızlandırır.

Ön İşleme(Preprocessing): Tüm fotoğrafların gri tona çevrilmesi veya belirli bir boyuta (örn: 640x640) yeniden boyutlandırılması(resize) gibi standartlaştırma işlemleri yapılır.

Augmentation Uygulama:Kod yazmadan döndürme, gürültü ekleme, kesme gibi artırma teknikleri seçilerek veri seti örneğin 3 katına çıkarılır.

Dışa Aktarma (Export): Hazır veri seti, YOLOv8, v7, v5 formatlarında veya TFRecord, COCO JSON formatlarında indirilebilir veya API kodu ile doğrudan Google Colab ortamına çekilebilir.


#### Diğer Veri Etiketleme Platformları

**LabelImg**  

**Avantajları:** Açık kaynak, internet gerektirmez, kurulumu çok basittir (Python tabanlı). Hızlıca YOLO (txt) veya PascalVOC (xml) çıktısı verir.  

**Dezavantajları:** Büyük veri setleri için yönetim zor, augmentation desteği yok. Sadece dikdörtgen kutu (bounding box) çizebilir, segmentasyon (poligon) yapamaz. Augmentation özelliği yoktur.

**CVAT (Computer Vision Annotation Tool)**  

**Avantajları:** Profesyonel seviyede araçlar, çoklu kullanıcı desteği, polygon, mask ve keypoint gibi farklı etiketleme türlerini destekler.  

**Dezavantajları:** Kurulumu ve kullanımı biraz daha teknik ve karmaşık

**Labelbox / Supervisely**  

**Avantajları:** Bulut tabanlı, takım çalışmasına uygun, gelişmiş analytics ve yönetim araçları.  

**Dezavantajları:** Ücretli planlar gereklı

---

### Google Colab Ortamında YOLO Eğitimi ve Nesne Tespiti
1. GPUyu aktif etmek

Runtime → Change runtime type → Hardware accelerator → GPU

2. Kütüphane kurulumu

```
!pip install ultralytics

```

3. YOLO modelinin yüklenmesi(s,m,l,x)

```
from ultralytics import YOLO
model = YOLO("yolov8s.pt")
```
4. YOLO veri setinin belirli bir klasör yapısında olmasını ve etiketlerin .txt formatında (YOLO formatı) hazırlanması gereklidir
dataset/

├── train/

│ ├── images/

│ └── labels/

├── val/

│ ├── images/

│ └── labels/

└── data.yaml #konfigurasyon dosyası 

yaml dosyası içeriği aşağıdaki gibi olabilir: 

path: /content/dataset

train: train/images

val: val/images

nc: 2
names: ["class1", "class2"]


5. Model eğitimi
```
model.train(
   data="dataset/data.yaml",
   epochs=50,
   imgsz=640,
   batch=16
)
```
epochs:eğitim döngüsü sayısı

imgsz:giriş görüntü boyutu

batch:batch size

data:veri seti konfigürasyon dosyası

çıktılar: runs/detect/train/

6. Nesne Tespiti(Detection)
```
model.predict(
    source="test.jpg",
    conf=0.25
)
```
prediction sonuçları: runs/detect/predict/



