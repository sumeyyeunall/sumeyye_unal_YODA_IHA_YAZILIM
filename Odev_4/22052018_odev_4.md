
Kaynak: https://ibmcsr.udemy.com/course/python-for-computer-vision-with-opencv-and-deep-learning

### Basics of OpenCV
#### Görüntü Okuma:

```
cv.imread('dosya_yolu') fonksiyonu kullanılır. Bu fonksiyon, belirtilen yoldaki görüntüyü bir piksel matrisi olarak döndürür.
```
```
cv.imshow('pencere_adi', goruntu_matrisi) fonksiyonu, görüntüyü yeni bir pencerede gösterir.
```
```
cv.waitKey(0) fonksiyonu, bir tuşa basılana kadar pencerenin açık kalmasını sağlar. Bu, imshow'un düzgün çalışması için zorunludur.
```
Not:büyük boyutlu görüntülerin ekran çözünürlüğünü aşması durumu sadece yeniden boyutlandırma ile çözülebilir.

#### Video Okuma:
```
capture = cv.VideoCapture(kaynak) ile bir video yakalama nesnesi oluşturulur. kaynak bir dosya yolu veya kamera indeksi (genellikle 0 webcam için) olabilir.
```
Videolar, bir while döngüsü içinde capture.read() metodu ile kare kare okunur. Bu metod, karenin başarıyla okunup okunmadığını belirten bir boolean (isTrue) ve karenin kendisini (frame) döndürür.
Her kare cv.imshow() ile gösterilir.

Döngüden çıkmak için cv.waitKey(gecikme_ms) fonksiyonu bir tuş basımını kontrol etmek için kullanılır.

İşlem bittiğinde kaynakların serbest bırakılması için capture.release() ve cv.destroyAllWindos() çağrılır. 

### Yeniden Boyutlandırma ve Ölçeklendirme

Görüntü ve videoları yeniden boyutlandırmanın temel amacı, büyük medya dosyalarının neden olduğu işlem yükünü azaltmaktır.

``` 
cv2.resize(src, dsize, fx, fy, interpolation)
*yaygin interpolasyon yöntemleri 
cv2.INTER_AREA: Görüntü küçültülürken kullanılır. Pikselleri yeniden örnekleyerek en iyi sonucu verir ve harelenmeyi(moire effect) önler.
cv2.INTER_LINEAR: Varsayılan yöntemdir. Hem büyütme hem küçültme için hızlı ve ortalama bir sonuç verir.
cv2.INTER_CUBIC: Görüntü büyütülürken kullanılır. INTER_LINEAR'a göre daha yavaştır ama daha keskin ve kaliteli sonuç üretir.
``` 
```
Örn: 
import cv2
img = cv2.imread('large_image.jpg')
#sabit boyutlandirma:500x500 piksel boyutuna getir
resized_fixed = cv2.resize(img, (500, 500))
# aspect ratio: görüntüyü %50 oranında küçültme
#dsize=None verilmeli, fx ve fy kullanılmalıdır.
resized_scaled = cv2.resize(img, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)
cv2.imshow("Sabit", resized_fixed)
cv2.imshow("Olcekli", resized_scaled)
cv2.waitKey(0)
```
Video işleme projelerinde FPS(frame per second) değerini artırmak için genellikle her kare/frame işleme girmeden önce küçültülür.
```
def rescale_frame(frame, scale=0.75):
    #görüntü boyutlarını al ve scale ile çarp
    width = int(frame.shape[1] * scale)
    height = int(frame.shape[0] * scale)
    dimensions = (width, height)
    
    return cv2.resize(frame, dimensions, interpolation=cv2.INTER_AREA)
```





## Image Processing 
Dijital görüntüler sayısal bir matris olarak kabul edilir. 

Piksel, görüntünün en küçük yapı birimidir. Her piksel, ışık yoğunluğunu temsil eden bir skaler (gri tonlamalı) veya vektörel (renkli) değer taşır. Pikseller sadece ışık şiddetini ifade eder. 

Matris Yapısı, HxWxC(Yükseklik, Genişlik, Kanal Sayısı) boyutlarında NumPy dizileri (arrays) olarak işlenir. Standart görüntü işlemede veri tipi genellikle uint8 formatındadır ve [0,255] aralığında değer alır. 0 siyahı, 255 beyazı temsil eder. 

### Color Mappings
Renk uzayları, renklerin sayısal olarak nasıl ifade edildiğini belirleyen matematiksel modellerdir. Farklı problemler, farklı renk uzaylarında daha kolay çözülür.

BGR ve RGB: OpenCV kütüphanesi görüntüleri varsayılan olarak BGR (Blue-Green-Red) diziliminde okur. Ancak yaygın görüntüleme kütüphaneleri (Matplotlib vb.) ve insan algısı RGB düzenini kullanır. Bu uyumsuzluk, kanal dönüşümü yapılmasını gerektirir.

``` 
Örn. RGB-GrayScale Dönüşümü (3 kanaldan 1kanala)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) 
``` 

HSV (Hue, Saturation, Value) ve HLS: Nesne takibi ve segmentasyon işlemlerinde ışık değişimlerinden (gölge vb.) etkilenmemek için RGB yerine HSV uzayı tercih edilir.

Hue:Rengin kendisini (kırmızı,mavi vb.) temsil eder. Işık değişimlerinden bağımsızdır.

Saturation(Doygunluk): Rengin canlılığını ifade eder.

Value/Lightness: Işık şiddetini ifade eder.
``` 
Örn. BGR'den RGB'ye çevirme
img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
Örn. BGR'den HSV'ye çevirme
img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
``` 

### Blending and Pasting
Blending: İki görüntünün piksel değerlerinin belirli ağırlıklarla toplanarak (linear combination) yumuşak bir geçişle birleştirilmesidir. Burada alpha ve beta görüntülerin şeffaflık/baskınlık oranını belirler. gamma ise sonuca eklenen sabit parlaklık değeridir.

Pasting: Bir görüntünün başka bir görüntü(arka plan gibi) üzerine doğrudan kopyalanmasıdır. ROI(region of interest), büyük resim üzerinde, küçük resmin yerleştirileceği koordinat alanıdır.

Not: bu işlemde piksel değerleri toplanmaz overwrite edilir. Yapıştırılacak görüntü boyutları ile hedef ROI birebir aynı olmalıdır aksi halde matris hatası alınır. 

dst = α⋅img1 + β.img2 +γ

Maskeleme: Dikdörtgen olmayan (düzensiz şekilli) ilgi alanlarının (ROI - Region of Interest) işlenmesi için kullanılır. Maske, orijinal görüntüyle aynı boyutlarda olan, genellikle 8-bitlik (tek kanallı) bir siyah-beyaz matristir.

Beyaz Bölgeler (Değer: 255 veya 1): İşleme dahil edilecek, korunacak veya kopyalanacak alanı temsil eder(ROI).

Siyah Bölgeler (Değer: 0): İşlem dışı bırakılacak, şeffaf sayılacak veya silinecek alanı temsil eder.

Örn.
``` 
img1 = cv2.imread("image.jpg")
img2 = cv2.imread("logo.jpg")
#blending aynı boyutta olmalı o yüzden resize(img2yi img1 boyutuna getiriyoruz)
img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))
blended = cv2.addWeighted(img1, 0.7, img2, 0.3, 0)
#pasting
img1_original = cv2.imread("image.jpg")
small_logo = cv2.resize(cv2.imread("logo.jpg"), (100, 100))
# ROI belirleme(sol üst köşe: x=0, y=0) // logonun yüksekliği ve genişliği kadar alan
rows, cols, channels = small_logo.shape
roi = img1_original[0:rows, 0:cols]
#piksel değerlerini atama
img1_original[0:rows, 0:cols] = small_logo
cv2.imshow("Pasting Ornegi", img1_original)
cv2.waitKey(0)
cv2.destroyAllWindows()
```
#### Bitwise Operatörler 

AND:İki resmin (veya maskenin) kesişimini alır. Siyah (0) olan yerler siyah kalır. Maskeyi resme giydirmek için kullanılır.
NOT: Maskeyi ters çevirir (Siyahlar beyaz, beyazlar siyah olur).

```
#Mask(beyaz) olan yerleri ana resimden al
img1_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)
#Mask(siyah) olan yerleri logodan al
img2_fg = cv2.bitwise_and(logo, logo, mask=mask)
```

### Histogramlar ve Eşitleme

Histogram, görüntüdeki piksel yoğunluklarının dağılımını gösteren grafiktir. Eşitleme/equalization ise görüntünün kontrastını artırmak için kullanılır.Özellikle düşük ışıklı ortamlarda detayları ortaya çıkarmak için etkilidir.
```
cv2.calcHist() fonksiyonu kullanılır.
Örn kod:
#Histogram eşitleme(sadece gri tonlamalı resimler için)
img = cv2.imread('low_contrast.jpg', 0)
equ = cv2.equalizeHist(img)
cv2.imshow('Original vs Equalized', np.hstack((img, equ)))

```

### Image Thresholding 
Gri tonlamalı bir görüntüyü, ikili (binary) görüntüye dönüştürme işlemidir. Görüntü bölütleme (segmentation) için temel adımdır.

 Simple thresholding: Basit bir eşik değeri belirlenir(T), p(x,y) > T ise piksel 255 değilse 0 atanır. 

 Adaptive thresholding: Işıklandırmanın homojen olmadığı görüntülerde kullanılır. Görüntü küçük pencerelere bölünür ve her bölge için yerel bir eşik değeri hesaplanır (Gaussian veya Mean yöntemleriyle).
``` 
#grayscale adaptive için 
img = cv2.imread('belge_fotografi.jpg', 0)
# threshold parametrelee:(img, MaxDeğer, yöntem, tip, blokboyutu, c_sabiti)
th_img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
#sonuc
cv2.imshow('Adaptif Sonuc', th_img)
``` 

### Blurring and Smoothing
Görüntüdeki yüksek frekanslı içerikleri (gürültü, keskin kenarlar) bastırmak için Alçak Geçiren Filtreler (Low Pass Filters) kullanılır. Bu işlem konvolüsyon (convolution) adı verilen, bir kernel matrisinin görüntü üzerinde gezdirilmesiyle yapılır.

 Average Blur: Kernel altındaki pikselerin aritmetik ortalamasını alır.

 Gaussian Blur: Merkeze yakın piksellere daha fazla ağırlık veren bir çan eğrisi fonksiyonu kullanır. Daha doğal bir yumuşatma sağlar.

 Median Blur: Kernel altındaki pikselleri sıralar ve medyanı alır. Salt & Pepper gürültüsünü temizlemede en etkili yöntemdir çünkü kenarları korur (non-linear filter).

 Bilateral Filter: Hem gaussiani hem de piksel yoğunluk farkını dikkate alır. Bu sayede doku yumuşatılırken kenarlar keskin kalır.

Not:Salt and pepper noise, dijital görüntü işlemede sıkça karşılaşılan, görüntü üzerinde rastgele dağılmış siyah ve beyaz noktalardan oluşan bir bozulma türüdür.


``` 
img = cv2.imread('gurultulu_resim.jpg')
#matplotlip icin bgr to rgb donusumu
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#blurring yontemleri
# 1. mean blur: (5, 5) -> Kernel boyutu. Sadece ortalama alir.
blur_mean = cv2.blur(img, (5, 5))
# 2. gaussian blur: (5, 5) -> Kernel boyutu. 0 -> SigmaX değeri (0 verilirse kernel boyutuna göre otomatik hesaplanır).
blur_gauss = cv2.GaussianBlur(img, (5, 5), 0)
#3. median blur 5 -> Kernel boyutu (Sadece tek bir sayı girilir, kare matris oluşturur). Salt n pepper gürültüsünde en etkilisi budur.
blur_median = cv2.medianBlur(img, 5)
``` 
### Morphological Operators 
Genellikle binary(siyah-beyaz) görüntülerde şekil ve yapı analizi için kullanılan küme teorisi tabanlı işlemlerdir. Bir yapılandıran eleman (structuring element) kullanılır.

 Erosion (Aşındırma): Ön plandaki nesnelerin sınırlarını aşındırır. Küçük beyaz gürültüleri yok eder ve birbirine ince bağlarla bağlı nesneleri ayırır.

 Dilation (Genişletme): Ön plandaki nesneleri genişletir. Kopuk parçaları birleştirir.

 Opening (Açma): Önce Erosion, sonra Dilation işlemidir. Nesne boyutunu değiştirmeden arka plan gürültülerini temizler.

 Closing (Kapama): Önce Dilation, sonra Erosion işlemidir. Nesne üzerindeki küçük delikleri (siyah noktaları) kapatır.

 Morphological Gradient: Dilation ile Erosion arasındaki farktır. Nesnenin dış hatlarını (konturlarını) verir.


``` 
def demonstrate_morphology():
    #basic goruntulu olusturma simulasyonu
    img = np.zeros((300, 300), dtype=np.uint8)
    cv2.putText(img, 'j', (80, 200), cv2.FONT_HERSHEY_SIMPLEX, 7, (255), 25)
    #noise ekleme
    # 'Opening' icin beyaz nokta gurultusu
    noise_white = np.random.randint(0, 2, (300, 300)) * 255
    mask_white = np.random.rand(300, 300) < 0.98 
    noise_white[mask_white] = 0
    img_opening_input = cv2.add(img, noise_white.astype(np.uint8))
    # 'Closing' testi icin siyah noktalar(dleikler)
    img_closing_input = img.copy()
    noise_black_mask = np.random.rand(300, 300) < 0.98
    img_closing_input[np.where((img == 255) & (noise_black_mask == False))] = 0
    # 5x5 boyutunda, 1'lerden oluşan kare matris kernel
    kernel = np.ones((5, 5), np.uint8)
    #1. Erosion nesneyi inceltir
    erosion = cv2.erode(img, kernel, iterations=1)
    #2. Dilation nesneyi kalınlaştırır
    dilation = cv2.dilate(img, kernel, iterations=1)
    #3. Opening: Erosion + Dilation: arka plandaki beyaz gürültüleri yok eder
    opening = cv2.morphologyEx(img_opening_input, cv2.MORPH_OPEN, kernel)
    #4. Closing: Dilation + Erosion : nesne içindeki siyah delikleri kapatmak
    closing = cv2.morphologyEx(img_closing_input, cv2.MORPH_CLOSE, kernel)
    #5. Morphological Gradient: Dilation – Erosion: nesnenin dış hatlarını (konturunu) çıkarır
    gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)
``` 


### Gradients 
Gradyan, bir görüntüde parlaklık değişiminin miktarını ve yönünü ifade eder. Parlaklık birden değişiyorsa(türev yüksekse) orada kenar(edge) vardır. Yüksek Geçiren Filtreler (High Pass Filters) kategorisindedir. Sobel, Scharr ve Laplacian gibi operatörler, kenarları çıkarmak için gradyan hesaplar. Gradyanlar nesne tespiti, segmentasyon, kontur bulma gibi işlemlerin temelidir. X yönündeki değişim dikey kenarları, Y yönündeki değişim yatay kenarları sağlar.

 Sobel Operatörü: Sobel operatörü, bir görüntünün birinci türevini hesaplayarak kenarları tespit eder.Hem türev hem de hafif bir Gaussian smoothing içerdiği için gürültüye dayanıklıdır. 

``` 
dst = cv2.Sobel(src, ddepth, dx, dy, ksize)
*src: grayscaled goruntu genellikle renkli goruntude her kanal icin ayri hesaplama yapilması islemi yavaslattigindan
*ddepth: cikti goruntusuunun veri tipidir. Normalde resimler uint8(0-255) formatindadir. Sobel turev aldigindan beyazdan siyaha geçişlerde sonuç negatif çıkar. Buraya cv2.CV_8U(veya -1) yazildiginda negatif degerler 0’a yuvarlanir ve kenarların yarısı kaybolur. Bu yüzden cv2.CV_64F yazılır bu sayede negatif kenar bilgileri hafızada tutulur. 
*dx: X eksendeki türev derecesi 
*dy: Y eksendeki türev derecesi 
*ksize:kernel size yani Sobel çekirdeğinin boyutu, 1 3 5 7 gibi bir tek sayı olmalıdır standart olarak 3 veya 5 kullanılır. Değer büyürse(örn 7) kalın kenarları bulur ama ince detayları kaybeder. 
```

 Laplacian Operatörü: Görüntünün ikinci türevini hesaplar. Yoğunluk değişiminin ivmesini ölçerek kenarları her yönden tespit eder, ancak gürültüye karşı çok hassastır. Yön bağımsızdır. X ve Y yönlerini aynı anda işler 
```
dst = cv2.Laplacian(src, ddepth, ksize)
```


Not: Sobel ve Laplacian sonucunda elmizde negatif sayılar var bunu ekranda imshow() ile göremeyiz mutlak değer dönüşümü yapılmalıdır. Sayıları uint8 formatına dönüştürür sonuç imshow(9 ile gösterilebilir hale gelir.
```
dst = cv2.convertScaleAbs(src)
```
```
#goruntuyu griye cevirme
img = cv2.imread('img.jpg', 0)
#laplacian uygulama
laplacian = cv2.Laplacian(img, cv2.CV_64F)
#goruntulemek icin mutlak deger alma
laplacian = cv2.convertScaleAbs(laplacian)

#sobel X dikey cizgileri bulma
# dx=1, dy=0: sadece x eksenindeki değişim
sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)
sobelx = cv2.convertScaleAbs(sobelx)

#sobel Y yatay cizgileri bulma
# dx=0, dy=1: sadece y eksenindeki değişim.
sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)
sobely = cv2.convertScaleAbs(sobely)
```
## Video Basics 
Görüntü kaynağına bağlanmak için cv2 VideoCapture sınıfı kullanılır. Kaynak, dahili bir webcam, USB kamera veya bir video dosyası olabilir. 

Kameradan alınan görüntü boyutları varsayılan olarak float döner. Koordinat hesaplamalarında kullanmak için bu değerler int tipine dönüştürülmelidir.

cv2.VideoCapture(0): Bilgisayarın varsayılan kamerasına (webcam) bağlanır. cv2.VideoCapture('path/video.mp4'): Belirtilen dosya yolundaki videoyu okur.
Reading Frames: cap.read() fonksiyonu iki değer döndürür

	ret(boolean): okuma başarılı mı true or false

 	frame(array): yakalanan görüntü matrisi 

```
#kamera baglantisi
cap = cv2.VideoCapture(0)
#genislik ve yukseklik (int donusumu yapilmak zorunda)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#video dosyalari icin acilip acilmadigini kontrol etme
if cap.isOpened() == False:
    print("Dosya bulunamadi veya acilamadi")
while True:
    ret, frame = cap.read()
    #videonun sonuna gelindiyse donguyu kir (video dosyalari icin)
    if ret == False:
        break
    cv2.imshow('Video', frame)
    # 'q' tusuna basilirsa cikis
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
cap.release()
cv2.destroyAllWindows()
```


Writing  Video Files(Recording): İşlenen görüntüleri kaydetmek için VideoWriter sınıfı kullanılır. İşletim sistemine göre doğru FourCC (4-byte code) codec'inin seçilmesi gerekir.
Örn. Windows: *'VIDX'

Döngü içerisinde her frame, writer.write(frame) komutu ile dosyaya eklenir. 
```
#VideoWriter Tanimlama
# Parametreler: Dosya Yolu, Codec, FPS, (Genislik, Yukseklik)
writer = cv2.VideoWriter('student_capture.mp4', 
                         cv2.VideoWriter_fourcc(*'XVID'),
                         25, 
                         (width, height))
# Dongu icinde
writer.write(frame)
# Islem bitince serbest birak
writer.release()
```
Drawing on Video: Video akışı karelerden oluştuğu için, resim üzerine çizim yapma mantığı burada da geçerlidir. Ancak koordinatların tam sayı (integer) olması zorunludur. Float değerler cv2.rectangle gibi fonksiyonlarda hata verir, bu yüzden bölme işleminde // operatörü kullanılır.
```
#ekranin ortasina dikdortgen cizme
#koordinatlar integer olmali(// kullanimi)
x = width // 2
y = height // 2
w = width // 4
h = height // 4
#dongu icinde her kareye cizilir
cv2.rectangle(frame, (x, y), (x+w, y+h), color=(0,0,255), thickness=4)
```

## Object Detection 

### Template Matching 
Büyük bir görüntü üzerinde, referans aldığımız küçük bir görüntüyü(template) kaydırarak tarama işlemidir. OpenCV, şablonu ana görüntünün her pikselinde gezdirir ve ne kadar örtüştüğünü hesaplar.  Kısaca küçük bir şablon görüntüsünü, daha büyük bir görüntü içinde en iyi eşleştiği yeri bulma yöntemi.
Eşleştirme:
```
res = cv2.matchTemplate(image, template, method)
Şablonun boyutuna göre küçültülmüş, her pikselin ne kadar eşleştiğini gösteren gri tonlamalı bir harita (heatmap) döner.
method: TM_CCOEFF, TM_CCOEFF_NORMED, TM_SQDIFF, vb.)
```
Konum bulma:
```
cv2.minMaxLoc(res)
Eşleşme haritasındaki en düşük ve en yüksek değerleri ve bunların konumlarını bulur: minVal, maxVal, minLoc, maxLoc değerlerini döndürür.
```
### Corner Detection 
Bir görüntüde "köşe", intensitynin tüm yönlerde büyük ölçüde değiştiği bölgelerdir. Edges sadece bir yönde değişim gösterirken, köşeler her yönde değişim gösterir.

	Harris Corner Detection

Gri tonlamalı görüntü float32 formatına çevrilir. Algoritma her piksel için bir skor hesaplar. Bu skorlar bir eşik değeri (threshold) ile filtrelenir ve köşeler belirlenir. 
```
cv2.cornerHarris(src, blockSize, ksize, k)
src: girdi görüntüsü ve float32 tipinde olmalı
blockSize:komşuluk boyutu köşe tespiti için 
ksize: Sobel türevi için kullanılan açıklık paramteresi örn 3 gibi
k: Harris dedektörü serbest parametresi(0.04 ve 0.06 arasında seçilik genellikle)
```
Harris algoritması sonucunda koordinat değil, bir yoğunluk haritası döner. Köşeleri görmek için şu adımlar izlenir:
Sonuç görüntüsü cv2.dilate ile genişletilerek işaretler belirginleştirilir. Maksimum değerin belirli bir yüzdesi (örn. %1'i) eşik olarak belirlenir ve bu değerden büyük olan yerler işaretlenir (Kırmızı renk atanır).

	Shi-Tomasi Corner Detection

"Good Features to Track" olarak da bilinir. Bu fonksiyon Harris gibi bir resim döndürmez; doğrudan köşelerin (x, y) koordinatlarını içeren bir liste döndürür. Çizim yapabilmek için bu float değerler tam sayıya (int64 veya np.int0) çevrilmelidir.

```
Örn. 
corners = cv2.goodFeaturesToTrack(gray, maxCorners=100, qualityLevel=0.01, minDistance=10)
for c in corners:
    x,y = c.ravel()
    cv2.circle(img, (int(x),int(y)), 4, (0,255,0), -1)
maxCorners: tespit edilecek maksimum köşe sayısı

qualityLevel: köşe kalitesi için minimum eşik değeri

minDistance: rtespit edilen iki köşe arasındaki minimum Öklid mesafesi

```
### Edge Detection 
Edge tespiti gürültüye çok hassastır. İlk adımda görüntüye 5x5'lik bir Gaussian filtresi uygulanarak gürültü temizlenir. Görüntünün yoğunluk gradyanı (türevi) hesaplanır (Sobel kernel kullanılarak). Parlaklığın hızla değiştiği yerler potansiyel kenardır. Kenarları inceltmek için kullanılır. Sadece yerel maksimum noktalar tutulur, diğerleri bastırılır. İki eşik değeri kullanılır: 

maxVal üzerindeki pikseller kesinlikle kenardır.

minVal altındaki pikseller atılır. 

```
blur = cv2.GaussianBlur(gray, (5,5), 1.4)
edges = cv2.Canny(blur, 50, 150)
```

#### Hough Transform

##### Hough Line Transform:Canny ile bulunan kenar görüntüsü üzerinde doğrular tespit edilir.

```
lines = cv2.HoughLines(edges, 1, np.pi/180, 200)
for line in lines:
    rho, theta = line[0]
    a = np.cos(theta)
    b = np.sin(theta)
    x0 = a * rho
    y0 = b * rho
    x1 = int(x0 + 1000*(-b))
    y1 = int(y0 + 1000*(a))
    x2 = int(x0 - 1000*(-b))
    y2 = int(y0 - 1000*(a))
    cv2.line(img, (x1,y1), (x2,y2), (0,0,255), 2)
*rho: mesafe çözünürlüğü/pikseli
*theta:acisal cozunurluk
*threshold:kac pikselin dogruda bulunması gerektiği 
```

##### Hough Circle Transform: Kenarlı bir görüntü üzerinde daireler tespit edilir.
```

circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=50,
                           param1=50, param2=30, minRadius=10, maxRadius=50)
if circles is not None:
    circles = np.uint16(np.around(circles))
    for i in circles[0,:]:
        cv2.circle(img, (i[0],i[1]), i[2], (0,255,0), 2)   # Daire
        cv2.circle(img, (i[0],i[1]), 2, (0,0,255), 3)      # Merkez noktası
*dp:accumalator cozunurlugu
*minDist: daire merkezleri arası min mesafe
```

### Grid Detection 
Bu işlem, görüntüdeki bozulmaları gidermek ve nesne takibinde referans noktaları oluşturmak için kullanılır. OpenCV'de en sık kullanılan iki yöntem: Chessboard Detection ve Circle Grid Detection

	Chessboard Detection 

Amaç, siyah ve beyaz karelerin kesiştiği iç köşe noktalarını bulmaktır. 
```
found, corners = cv2.findChessboardCorners(image, patternSize, flags)
patternSize: (sütun, satır) formatında bir tuple.
Not: Buraya tahtadaki kare sayısını değil, iç köşe (kesişim) sayısını yazmalıyız. Örneğin, kenarları 8 kare olan standart bir satranç tahtasında iç köşeler 7 adettir. Yani boyut (7, 7) olur.
found (ret): boolean true false desen bulundu mu
corners: bulunan köşe noktalarının koordinat listesi
```
	Circle Grid Detection

Kare köşeleri yerine dairelerin merkezlerini bulur.
```
found, corners = cv2.findCirclesGrid(image, patternSize, flags)
flags: genellikle cv2.CALIB_CB_SYMMETRIC_GRID flagi kullanılır.
Cizim için ikisinde de cv2.drawChessboardCorners fonksiyonu kullanılır çıktı formatları aynı  
```
### Contour Detection
Kontur tespiti genellikle ikili (binary) görüntüler üzerinde yapılır. Bu yüzden işlemden önce görüntünün siyah-beyaz (threshold) hale getirilmesi veya Canny kenar tespiti uygulanması gerekir. Kısaca amaç nesnelerin dış sınırlarını bulup şekil analizi, boyutlandırma, eşikleme sonrası nesne çıkarımı yapmak.
```
image, contours, hierarchy = cv2.findContours(image, mode, method)
mode: konturların nasıl alınacağını ve hiyerarşinin nasıl kurulacağını belirler. Örn cv2.RETR_CCOMP 
method: kontur noktalarının nasıl saklanacağını belirler. Örn cv2.CHAIN_APPROX_SIMPLE gereksiz noktaları atar bu sayede bellek tasarrufu sağlanır.
```

### Feature Matching 
Bu teknik, bir görüntüdeki belirgin özellikleri (keypoints) bulup, başka bir görüntüdeki (döndürülmüş, küçültülmüş veya açısı değişmiş) aynı özelliklerle eşleştirmeyi sağlar. Kısaca amaç görüntüler arasında ortak anatomik noktaları bulmak (örn. panorama, 3D rekonstrüksiyon). Yöntemler:
Brute-Force (BF) Matcher: Bir görüntüdeki her özelliği diğerindeki tüm özelliklerle tek tek kıyaslar.
ORB: Hızlıdır, ikili (binary) descriptor kullanır. Mesafe ölçümü için cv2.NORM_HAMMING gerektirir.
SIFT: Daha hassastır. Yanlış eşleşmeleri elemek için Lowe's Ratio Test (En iyi eşleşme < 0.75 * İkinci en iyi) uygulanır.
FLANN Based Matcher: Büyük veri setlerinde BF'den çok daha hızlı çalışan, yaklaşık en yakın komşuyu bulan algoritmadır.
```
orb = cv2.ORB_create(nfeatures=1000)
kp, des = orb.detectAndCompute(gray, None)
img_kp = cv2.drawKeypoints(img, kp, None, flags=0)
```
### Watershed Algorithm
Görüntü bölümleme (segmentation) için kullanılır. Özellikle birbirine dokunan veya üst üste binen nesneleri (örneğin yan yana duran madeni paralar) ayırmak için çok etkilidir. Görüntüyü topografik bir harita gibi düşünür. Parlak yerler "tepe", karanlık yerler "vadi"dir. Vadilere su doldurulur; suların birleştiği yerlere "baraj" (watershed) kurulur. Bu barajlar nesne sınırlarını oluşturur. İşlem adımları şu şekildedir:

Preprocessing: Görüntüye Median Blur ve Otsu Threshold uygulanır.

Noise Removal: Morphological Opening ile gürültüler temizlenir.

Sure Foreground (Distance Transform): Nesnelerin merkez noktaları (çekirdekleri) bulunur. Bu adım yapışık nesneleri ayırır.

Markers: Bilinen nesneler etiketlenir, bilinmeyen (sınır) bölgeler 0 olarak işaretlenir.

Result: Algoritma sınırları bulduğunda o pikselleri -1 değeri ile işaretler.
```
#distance transform
dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
ret, sure_fg = cv2.threshold(dist_transform, 0.7*dist_transform.max(), 255, 0)
 #algoritma uygulama
markers = cv2.watershed(img, markers)
img[markers == -1] = [255, 0, 0] #sınırları kırmızı yapma
```
### Custom Seeds with Watershed Algorithm
Önceki otomatik Watershed algoritmasından farklı olarak, bu yöntem etkileşimli (interactive) bölütleme sağlar. Kullanıcı, fare ile nesneleri işaretleyerek algoritmanın nereden başlayacağını (seeds) belirler.
Kullanıcı bir görüntü üzerinde segmentlere ayırmak istediği bölgeleri fare tıklamalarıyla seçer. Her tıklama (0-9 arası tuşlarla seçilen) farklı bir tamsayıyı (etiketi) temsil eder ve görsel olarak farklı renklerle gösterilir. Watershed algoritması, kullanıcının verdiği bu "tohumları" (seeds) başlangıç noktası olarak alır ve görüntüyü bu etiketlere göre doldurarak sınırları çizer.
```
#fare tıklamalarını yakala ve markerları oluştur
def mouse_callback(event, x, y, flags, param):
    if event == cv2.EVENT_LBUTTONDOWN:
        #tıklanan noktayı marker matrisine(current_marker) işleöe
        cv2.circle(marker_image, (x, y), 10, (current_marker), -1)
        cv2.circle(segments, (x, y), 10, current_marker, -1)
#watershed uygulama
cv2.watershed(road_copy, segments)
```
### Face Detection(Haar Cascades)
Yüz, göz veya plaka gibi nesneleri tespit etmek için kullanılan en eski ve hızlı yöntemlerden biridir. Viola-Jones algoritmasına dayanır. 

Piksellerin yoğunluk farklarına (karanlık/aydınlık bölgeler) bakar. Örneğin, göz bölgesi genellikle yanaklardan daha karanlıktır. Binlerce özellik tek seferde kontrol edilmez. Özellikler aşamalara ayrılır. Eğer bir bölge ilk aşamayı geçemezse hemen elenir. Bu sayede işlem çok hızlıdır. Önceden eğitilmiş modeller (yüz, göz, gülümseme vb.) .xml dosyaları olarak OpenCV ile gelir.

OpenCV'de detectMultiScale fonksiyonu bu işlemi yönetir:

scaleFactor:Görüntü Piramidi (Image Pyramid) oluşturarak farklı uzaklıktaki (boyuttaki) yüzlerin tespit edilmesini sağlar. 1.1 değeri görüntüyü her adımda %10 küçültür.

minNeighbors:Hatalı tespitleri (False Positives) engellemek için kullanılır. Bir bölgenin yüz sayılması için en az kaç adet doğrulayıcı dikdörtgen (candidate) gerektiğini belirtir. Genellikle 3 ile 6 arasında seçilir.

Not: Haar Cascade yoğunluk farkına baktığı için görüntü işleme girmeden önce mutlaka cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ile gri tonlamaya çevrilmelidir.


```
img = cv2.imread('yuz.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #Griye çevirme şart

#Modeli yükle
face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')

#Yüz Tespiti
# 1.1: %10 küçültme oranı, 5: En az 5 komşu dikdörtgen onayı
face_rects = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)

for (x, y, w, h) in face_rects:
    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 255), 2)
```

### Object Tracking
Nesne takibi, bir nesnenin videodaki her karede konumunun bulunmasıdır. Karıştırılmaması gereken nokta:

Object Detection: Nesneyi ilk defa bulur.

Object Tracking: Bulunan nesnenin kareden kareye hareketini izler.
Tracking için kullanılan yöntemler:
Takip yaparken kullanılan yöntemler:

Optical Flow

MeanShift / CamShift

OpenCV Tracking API (KCF, CSRT, MIL, MOSSE, vb.)

#### Optical Flow
iki ardışık kare arasındaki piksel hareketini tahmin eder. Bir piksel bir sonraki karede çok küçük bir konuma kayar. Bu kayma miktarı (vx, vy) hesaplanır. En bilinen algoritmaları:  Lucas–Kanade Optical Flow (sparse, seçili noktaları takip eder), Farneback Optical Flow (dense, tüm piksellerin hareketini hesaplar) 
```
Örn 
import cv2
import numpy as np
cap = cv2.VideoCapture("video.mp4")
#ilk framei okuma
ret, old_frame = cap.read()
old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)
# tracking pointsi seçme
p0 = cv2.goodFeaturesToTrack(old_gray, 100, 0.3, 7)
#Lucas-Kanade parametreleri
lk_params = dict(winSize=(15, 15),
maxLevel=2,
criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))
mask = np.zeros_like(old_frame)
while True:
ret, frame = cap.read()
if not ret:
break
frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
#optical flow hesaplama
p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)

good_new = p1[st == 1]
good_old = p0[st == 1]
#hareket çizgileri 
for i, (new, old) in enumerate(zip(good_new, good_old)):
x1, y1 = new.ravel()
x2, y2 = old.ravel()
cv2.line(mask, (x1, y1), (x2, y2), (0,255,0), 2)
cv2.circle(frame, (x1, y1), 5, (0,0,255), -1)
img = cv2.add(frame, mask)
cv2.imshow("Optical Flow", img)
old_gray = frame_gray.copy()
p0 = good_new.reshape(-1, 1, 2)
if cv2.waitKey(1) == ord("q"):
break
cap.release()
cv2.destroyAllWindows()
```
#### MeanShift and CamShift Tracking Theory
MeanShift: Bir histogram belirlenir(takip edilecek nesne). Windowsürekli olarak maksimum yoğunluklu bölgeye kaydırılır. Sabit boyutlu window kullanır.
CamShift(Continuously Adaptive MeanShift):MeanShift’in gelişmiş halidir. Window boyutunu otomatik olarak büyültür/küçültür. Dönen nesneleri takip edebilir.

```
#Videoda bir nesnenin (örneğin bir kutu, yüz, araba vb.) hareketini takip etmek için MeanShift algoritmasının kullanımı örneği
1) Videodan ilk kare alınır.
2) Takip edilmek istenen bölge (ROI) seçilir.
3) Bu bölgenin HSV histogramı çıkarılır (renk bilgisi).
4) Her yeni karede histogram geriye izdüşürülür(Back Projection). Bu işlem, nesnenin o karede nerede olabileceğini tahmin eder.
5)MeanShift algoritması en yoğun bölgeyi bulur ve pencereyi oraya taşır.
6) Sonuç olarak nesne kare boyunca takip edilir ve etrafına dikdörtgen çizilir.
import cv2
cap = cv2.VideoCapture("video.mp4")
ret, frame = cap.read()
#tracking penceresi (x,y,w,h)
track_window = (200, 150, 50, 50)
roi = frame[150:200, 200:250]
hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
roi_hist = cv2.calcHist([hsv_roi],[0],None,[180],[0,180])
cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)
term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)
while True:
    ret, frame = cap.read()
    if not ret:
        break
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)
    ret, track_window = cv2.meanShift(dst, track_window, term_crit)
    x, y, w, h = track_window
    cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 2)
    cv2.imshow('MeanShift', frame)
    if cv2.waitKey(1) == ord('q'):
        break
```

#### OpenCV Tracking API 
Bir videodaki nesneyi kareden kareye takip etmek için hazır algoritmalar sağlar. Bu algoritmalar tek seferlik bir başlangıç bounding boxı ister. Sonra her karede nesnenin konumuunu tahmin eder. Özellikle gerçek zamanlı uygulamalarda kullanılır (drone, robot, güvenlik kamerası vb.)
Pratikte en hızlısı: MOSSE
En kararlısı: CSRT 
Gerçek zamanlı güçlü takip: KCF

##### Kısaca çalışma şekli
İlk karede kullanıcı bir bounding box seçer. Seçilen bölgenin özellikleri çıkarılır:HOG (Histogram of Oriented Gradients), Color Histograms, Kanal filtreleri. Tracker her yeni karede bu özellikleri karşılaştırarak nesnenin en benzer olduğu yeni bölgeyi arar. 

```
Örn kod:
import cv2
cap = cv2.VideoCapture("video.mp4")
#ilk kare
ret, frame = cap.read()

#kullanıcıya ROI seçtirme
bbox = cv2.selectROI("Frame", frame, False)

#örn CSRT trackeri 
tracker = cv2.TrackerCSRT_create()
tracker.init(frame, bbox)
while True:
    ret, frame = cap.read()
    if not ret:
        break
    #her karede konumu güncelle
    success, bbox = tracker.update(frame)
    if success:
        x, y, w, h = [int(v) for v in bbox]
        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 2)
        cv2.putText(frame, "Tracking", (20,40),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
    else:
        cv2.putText(frame, "Lost", (20,40),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)
    cv2.imshow("Tracking", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
cap.release()
cv2.destroyAllWindows()
```

